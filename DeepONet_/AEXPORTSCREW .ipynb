{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data for the screw extrusion process model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JQXTWz35c40",
    "outputId": "687a5ea4-75cb-47ae-aaba-7392fe192103"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lab422/422File/Class_2023/zt/2025/Adaptivedesign10/data\n",
      "/home/lab422/422File/Class_2023/zt/2025/Adaptivedesign10/data\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import numpy as np\n",
    "from jax import random\n",
    "from tqdm import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "from SCREW import screwModel\n",
    "IMPORT_PATH = os.getcwd()\n",
    "print(IMPORT_PATH)\n",
    "%matplotlib inline\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "from scipy.stats.qmc import LatinHypercube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################模型求解#################\n",
    "Z=200\n",
    "tmax=200\n",
    "dt=1\n",
    "N_train = 3000#1000 # number of input samples\n",
    "N_test = 500#500\n",
    "# Select N keys to create N Functions\n",
    "key = random.PRNGKey(0)\n",
    "keys = random.split(key, N_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "采样结果形状: (3000, 3)\n"
     ]
    }
   ],
   "source": [
    "def generate_lhs_samples(n_params=3, n_samples=N_train, param_ranges=None, seed=42):\n",
    "    \"\"\"\n",
    "    :param n_params: \n",
    "    :param n_samples: \n",
    "    :param param_ranges: \n",
    "    :param seed: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "\n",
    "    if len(param_ranges) != n_params:\n",
    "        raise ValueError(\"参数范围列表的长度必须与参数数量相等\")\n",
    "    \n",
    "    samples = np.zeros((n_samples, n_params))  \n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    seeds = rng.integers(0, 1e6, size=n_params)  \n",
    "    \n",
    "    for i, (lower, upper) in enumerate(param_ranges):\n",
    "        sampler = LatinHypercube(d=1, seed=seeds[i])  \n",
    "        raw_samples = sampler.random(n_samples).flatten() \n",
    "        scaled_samples = lower + (upper - lower) * raw_samples  \n",
    "        samples[:, i] = scaled_samples  \n",
    "    \n",
    "    return samples\n",
    "\n",
    "\n",
    "\n",
    "param_ranges = [(1e-3, 2e-1), (1e-2, 3), (1, 30)]\n",
    "seed = 111\n",
    "samples = generate_lhs_samples(param_ranges=param_ranges, n_samples=N_train, seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array 1 shape: (3000, 200)\n",
      "Array 2 shape: (3000, 200)\n",
      "Array 3 shape: (3000, 200)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "samples_split = [samples[:, i] for i in range(samples.shape[1])]#<class 'list'>\n",
    "\n",
    "\n",
    "expanded_samples = [np.tile(sample, (Z, 1)).T for sample in samples_split]#<class 'list'>\n",
    "mu1s, mu2s, alphas= expanded_samples\n",
    "\n",
    "# 打印结果，检查每个数组的维度\n",
    "for i, arr in enumerate(expanded_samples):\n",
    "    print(f\"Array {i+1} shape: {arr.shape}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BS3cApE9674l"
   },
   "source": [
    "## Training Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORw11jP8xpgg"
   },
   "source": [
    "\n",
    "\n",
    "We need to generate 5000 functions, so lets create a function to help us with the training and testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ffEaJ96I704M"
   },
   "outputs": [],
   "source": [
    "# Geneate training data corresponding to one input sample\n",
    "def generate_one_training_data(key,Z,tmax,dt,param):\n",
    "    mu1, mu2, alpha = param\n",
    "    # Numerical solution\n",
    "    model = screwModel(key,Z,tmax,dt,mu1, mu2, alpha)\n",
    "    xx,tt,fp,T,lt0,sensor_values1,sensor_values2,sensor_values3 = model.solve()\n",
    "    del model\n",
    "    gc.collect()  \n",
    "    return fp,T,lt0,sensor_values1,sensor_values2,sensor_values3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Data: 100%|████████████████| 3.00k/3.00k [15:08:45<00:00, 18.2s/step]\n"
     ]
    }
   ],
   "source": [
    "sensor_values1s = []\n",
    "sensor_values2s = []\n",
    "sensor_values3s = []\n",
    "fps = []\n",
    "Ts  = []\n",
    "lts = []\n",
    "# Sequentially generate data\n",
    "for i in tqdm(range(N_train), desc=\"Generating Data\", ncols=80,unit=\"step\", unit_scale=True):\n",
    "    \n",
    "    fp,T,lt0,sensor_values1, sensor_values2,sensor_values3 = generate_one_training_data(keys[i],Z,tmax,dt,samples[i, :])\n",
    "    fps.append(fp)\n",
    "    lts.append(lt0)\n",
    "    Ts.append(T)\n",
    "    sensor_values1s.append(sensor_values1)\n",
    "    sensor_values2s.append(sensor_values2)\n",
    "    sensor_values3s.append(sensor_values3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays for consistency\n",
    "sensor_values1s = np.array(sensor_values1s)\n",
    "sensor_values2s = np.array(sensor_values2s)\n",
    "sensor_values3s = np.array(sensor_values3s)\n",
    "\n",
    "Ts = np.array(Ts)#Ts.shape= (N, 200, 200)\n",
    "fps = np.array(fps)\n",
    "lts = np.array(lts)\n",
    "\n",
    "Ts = np.reshape(Ts, (-1, Z*tmax))#\n",
    "fps = np.reshape(fps, (-1, Z*tmax))\n",
    "lts_expanded = np.expand_dims(lts, axis=2)#\n",
    "lts_repeated = np.tile(lts_expanded, (1, 1, 200))\n",
    "ltss = np.reshape(lts_repeated, (-1, Z*tmax))#(N,Z*tmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"Train_3000.npz\"\n",
    "save_path = os.path.join(IMPORT_PATH, file_name)\n",
    "np.savez_compressed(save_path, sensor_values1=sensor_values1s, sensor_values2=sensor_values2s, sensor_values3=sensor_values3s, Ts=Ts,\\\n",
    "                    fps=fps,ltss=ltss,mu1s=mu1s, mu2s=mu2s, alphas=alphas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(0, 2, Z+1)\n",
    "space=x[:-1]\n",
    "time = np.arange(0, tmax , dt)\n",
    "xt = [(x0, y0) for x0 in space for y0 in time]\n",
    "np.savez_compressed(\"xt.npz\", xt=xt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Test Data: 100%|████████████████| 500/500 [2:36:31<00:00, 18.8s/step]\n"
     ]
    }
   ],
   "source": [
    "key = random.PRNGKey(1)\n",
    "keys = random.split(key, N_test)\n",
    "sensor_values1s0 = []\n",
    "sensor_values2s0 = []\n",
    "sensor_values3s0 = []\n",
    "fps0= []\n",
    "Ts0 = []\n",
    "lts0=[]\n",
    "\n",
    "param_ranges = [(1e-3, 2e-1), (1e-2, 3), (1, 30)]\n",
    "seed = 122\n",
    "samples_test = generate_lhs_samples(param_ranges=param_ranges, n_samples=N_test, seed=seed)\n",
    "\n",
    "\n",
    "samples_split2 = [samples_test[:, i] for i in range(samples_test.shape[1])]#<class 'list'>\n",
    "\n",
    "expanded_samples2 = [np.tile(samples_test, (Z, 1)).T for samples_test in samples_split2]#<class 'list'>\n",
    "mu1s2, mu2s2, alphas2= expanded_samples2\n",
    "\n",
    "for i in tqdm(range(N_test), desc=\"Generating Test Data\", ncols=80,unit=\"step\", unit_scale=True):\n",
    "\n",
    "    fp,T,lt0,sensor_values1, sensor_values2,sensor_values3 = generate_one_training_data(keys[i],Z,tmax,dt,samples_test[i,:])\n",
    "    fps0.append(fp)\n",
    "    lts0.append(lt0)\n",
    "    sensor_values1s0.append(sensor_values1)\n",
    "    sensor_values2s0.append(sensor_values2)\n",
    "    sensor_values3s0.append(sensor_values3)\n",
    "    Ts0.append(T)\n",
    "\n",
    "# Convert lists to numpy arrays for consistency\n",
    "sensor_values1s0 = np.array(sensor_values1s0)\n",
    "sensor_values2s0 = np.array(sensor_values2s0)\n",
    "sensor_values3s0 = np.array(sensor_values3s0)\n",
    "fps0=np.array(fps0)\n",
    "Ts0 = np.array(Ts0)\n",
    "lts0=np.array(lts0)\n",
    "Ts0 = np.reshape(Ts0, (-1, Z*tmax))\n",
    "\n",
    "Ts0 = np.reshape(Ts0, (-1, Z*tmax))\n",
    "fps0 = np.reshape(fps0, (-1, Z*tmax))\n",
    "lts0_expanded = np.expand_dims(lts0, axis=2)\n",
    "lts0_repeated = np.tile(lts0_expanded, (1, 1, 200))\n",
    "ltss0 = np.reshape(lts0_repeated, (-1, Z*tmax))#(N,Z*tmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor_values1s0.shape=  (500, 200)\n",
      "ltss0.shape=  (500, 40000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_name=\"Test_500.npz\"\n",
    "save_path = os.path.join(IMPORT_PATH, file_name)\n",
    "np.savez_compressed(save_path, sensor_values1=sensor_values1s0, sensor_values2=sensor_values2s0,sensor_values3=sensor_values3s0,\\\n",
    "                    Ts=Ts0,fps=fps0,ltss=ltss0,mu1s=mu1s2, mu2s=mu2s2, alphas=alphas2)\n",
    "\n",
    "print(\"sensor_values1s0.shape= \",sensor_values1s0.shape)\n",
    "print(\"ltss0.shape= \",ltss0.shape)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "9. DiffusionReaction(PI-DeepONet).ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "pytorch1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
